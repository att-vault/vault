{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import pytz\n",
    "\n",
    "import numpy as np\n",
    "from tables import *\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from skyfield import api\n",
    "from skyfield.sgp4lib import EarthSatellite\n",
    "from skyfield.framelib import itrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open up our reduced/cleaned TLE dataz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5path = \"/data/Indexed_TLE/reduced.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tle_dataframe(records):\n",
    "    return pd.DataFrame.from_records(records, columns=[\"epoch\", \"norad_id\", \"tle1\", \"tle2\"])\n",
    "\n",
    "def get_all_tles(norad_id: int):\n",
    "    \"\"\"\n",
    "    Return a pandas DataFrame, where rows correspond to a TLE\n",
    "    \n",
    "    (\n",
    "        epoch_time: float,\n",
    "        norad_id: int,\n",
    "        tle_line_1: bytes,\n",
    "        tle_line_2: bytes\n",
    "    )\n",
    "    \"\"\"\n",
    "    h5ro = open_file(h5path, mode=\"r\")\n",
    "    records = h5ro.root.tle_sorted.read_where(\"norad_id=={}\".format(norad_id))\n",
    "    h5ro.close()\n",
    "    # Sort records based on time\n",
    "    return tle_dataframe(sorted(records, key=lambda row: row[0]))\n",
    "\n",
    "def get_all_ids():\n",
    "    \"\"\"\n",
    "    Get all Norad ID that are present in this dataset in ascending order.\n",
    "    \"\"\"\n",
    "    h5ro = open_file(h5path, mode=\"r\")\n",
    "    results = set(h5ro.root.tle_sorted.cols.norad_id)\n",
    "    h5ro.close()\n",
    "    return list(sorted(results))\n",
    "\n",
    "max_extrap = timedelta(days=7).total_seconds()\n",
    "\n",
    "\n",
    "class TLEManager:\n",
    "    \"\"\"\n",
    "    This class is responsible for determining when and which TLE's are\n",
    "    valid/useful for a particular period in time. It additionally has\n",
    "    methods for computing Lat/Long/Dist data based on the windows\n",
    "    computes\n",
    "    \"\"\"\n",
    "    def __init__(self, norad_id: int):\n",
    "        self.records = get_all_tles(norad_id)\n",
    "        self._ts = api.load.timescale()\n",
    "        \n",
    "    def get_known_timespan(self):\n",
    "        \"\"\"\n",
    "        Return datetimes corresponding to the first and last TLE epoch values\n",
    "        in our record set\n",
    "        \"\"\"\n",
    "        times = self.get_tle_times()\n",
    "        return times[0], times[-1]\n",
    "    \n",
    "    def get_tle_times(self):\n",
    "        return self.records.epoch.to_numpy()\n",
    "    \n",
    "    def get_compute_windows(self):\n",
    "        \"\"\"\n",
    "        Calculate the windows over which all of the TLE's for this identifier are\n",
    "        valid. When used on a dataset pruned down for the AIS valid time periods,\n",
    "        this will automatically\n",
    "        \n",
    "        [\n",
    "          (start_epoch, end_epoch, tle1, tle2)\n",
    "        ]\n",
    "        \"\"\"\n",
    "        times = self.get_tle_times()\n",
    "        ntle = times.shape[0]\n",
    "        \n",
    "        windows = []\n",
    "        for i in range(ntle):\n",
    "            # For each TLE there is a window of time around that we will use to\n",
    "            # pre-compute the position of the satellite.\n",
    "            \n",
    "            # Logic for window starting\n",
    "            if i == 0:\n",
    "                # Handle the first record, no TLE before, so start centered on it\n",
    "                start = times[0]\n",
    "            else:\n",
    "                # If the time since the last TLE has been more than two weeks\n",
    "                # then start this window two weeks back\n",
    "                # Otherwise this window starts halfway between this and the last\n",
    "                # TLE to minimize the projection error\n",
    "                halfway_to_last = (times[i-1] + times[i]) /2\n",
    "                two_weeks_back = times[i] - max_extrap\n",
    "                start = max(halfway_to_last, two_weeks_back)\n",
    "            \n",
    "            # Logic for window ending\n",
    "            if i == ntle-1:\n",
    "                # Handle the last record. Do not project past it\n",
    "                end = times[-1]\n",
    "            else:\n",
    "                # If the time between this TLE and the next is more than two weeks\n",
    "                # project forward at most two weeks time, then close the window\n",
    "                halfway_to_next = (times[i] + times[i+1]) / 2\n",
    "                two_weeks_forward = times[i] + max_extrap\n",
    "                \n",
    "                end = min(halfway_to_next, two_weeks_forward)\n",
    "                \n",
    "            windows.append((int(round(start)), int(round(end)), self.records.tle1[i], self.records.tle2[i]))\n",
    "        \n",
    "        return windows\n",
    "    \n",
    "    def _epoch_to_julian(self, time: float) -> float:\n",
    "        return self._ts.from_datetime(datetime.utcfromtimestamp(time).replace(tzinfo=pytz.utc)).tt\n",
    "    \n",
    "    def compute_lat_long_dist(self, start_epoch: int, end_epoch: int, tle1, tle2):\n",
    "        \"\"\"\n",
    "        Given a pair of integer epoch times (in seconds)\n",
    "        Compute an array of times, lats, longs and distances.\n",
    "        \n",
    "        \n",
    "        \"\"\"\n",
    "        # Convert the start and end into julian\n",
    "        start_time_j = self._epoch_to_julian(start_epoch)\n",
    "        end_time_j = self._epoch_to_julian(end_epoch)\n",
    "        \n",
    "        n_time_steps = int(round((end_epoch - start_epoch) / 60))\n",
    "        \n",
    "        julian_times = self._ts.tt_jd(np.linspace(start_time_j, end_time_j, n_time_steps))\n",
    "        epoch_times = np.linspace(start_epoch, end_epoch, n_time_steps)\n",
    "        \n",
    "        sat = EarthSatellite(tle1.decode(), tle2.decode())\n",
    "        lats, longs, dists = sat.at(julian_times).frame_latlon(itrs)\n",
    "        \n",
    "        return epoch_times, lats.degrees, longs.degrees, dists.m\n",
    "\n",
    "    def compute_tlla_sequence(self):\n",
    "        windows = self.get_compute_windows()\n",
    "        to_concat = []\n",
    "\n",
    "        for start, end, tle1, tle2 in windows:\n",
    "            tlla = self.compute_lat_long_dist(start, end, tle1, tle2)\n",
    "            tlla = np.vstack(tlla)            \n",
    "            to_concat.append(tlla)\n",
    "\n",
    "        return np.hstack(to_concat).astype(np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19404"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This takes a couple seconds....\n",
    "all_ids = get_all_ids()\n",
    "len(all_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "windows = tlem.compute_tlla_sequence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "windows.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets really quick check that the windows we compute and the trajectories meet end-to-end for a semi-random data point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "fig.set_size_inches(20,  10)\n",
    "\n",
    "tlem = TLEManager(list(all_ids)[-3001])\n",
    "windows = tlem.get_compute_windows()\n",
    "\n",
    "for i, (start, end, tle1, tle2) in enumerate(windows):\n",
    "    times, lats, longs, alts = tlem.compute_lat_long_dist(start, end, tle1, tle2)\n",
    "  \n",
    "    ax1.set_title(\"Latitude\")\n",
    "    ax1.plot(times, lats, alpha=0.4)\n",
    "\n",
    "    ax2.set_title(\"Longitude\")\n",
    "    ax2.plot(times, longs, alpha=0.4)\n",
    "\n",
    "\n",
    "# Add vertical lines where there are TLE epochs\n",
    "xmin, xmax = ax1.get_xlim()\n",
    "for t in tlem.get_tle_times():\n",
    "    if(t > xmin and t < xmax):\n",
    "        ax1.axvline(t, ls=\"--\")\n",
    "        ax2.axvline(t, ls=\"--\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks ok at a cursory glance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_the_work(sat_id: int):\n",
    "    return TLEManager(sat_id).compute_tlla_sequence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying Dask:\n",
    "#from dask.distributed import Client, as_completed\n",
    "#client = Client(memory_limit='8GB')  # start local workers as processes\n",
    "#client\n",
    "\n",
    "# Trying concurrent.futures:\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "client = ProcessPoolExecutor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "precompute = open_file(\"/data/Indexed_TLE/precomp2.h5\", \"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created new group\n",
      "Already completed: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/19404 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "if not hasattr(precompute.root, \"sat\"):\n",
    "    print(\"Created new group\")\n",
    "    sat_group = precompute.create_group(\"/\", \"sat\", \"Precomputed satellite position cache\")\n",
    "else:\n",
    "    print(\"Found existing group\")\n",
    "    sat_group = precompute.get_node(\"/sat\")\n",
    "\n",
    "    \n",
    "already_completed = set(int(k.replace(\"s\", \"\")) for k in dir(sat_group) if not k.startswith(\"_\"))\n",
    "print(\"Already completed: %i\" % len(already_completed))\n",
    "todo_ids = set(all_ids).difference(already_completed)\n",
    "\n",
    "fut_to_id = {client.submit(do_the_work, sat_id): sat_id for sat_id in todo_ids}\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "with tqdm(total=len(fut_to_id)) as pbar:\n",
    "    pbar.update(len(already_completed))\n",
    "    for fut in as_completed(fut_to_id.keys()):\n",
    "        sat_id = fut_to_id[fut]\n",
    "        data = fut.result()\n",
    "\n",
    "        pbar.set_description(\"%i: %s\" % (sat_id, str(data.shape)))\n",
    "        # Create the hdf5 carray and populate it with the data\n",
    "        name = \"s\" + str(sat_id)\n",
    "        sat_array = Array(sat_group, name , data, title=\"Data for satellite with norad id: %s\" % sat_id)\n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precompute.close()\n",
    "client.shutdown(wait=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from tables import open_file\n",
    "import numpy as np\n",
    "\n",
    "computed = open_file(\"/data/Indexed_TLE/precomp-sample.h5\", mode=\"r\")\n",
    "sat_group = computed.get_node(\"/sat\")\n",
    "\n",
    "\n",
    "class SatelliteDataReader:\n",
    "    def __init__(self, h5_node):\n",
    "            self.node = h5_node\n",
    "\n",
    "    def get_satellites_contained():\n",
    "        return set(int(k.replace(\"s\", \"\")) for k in dir(self.node) if not k.startswith(\"_\"))\n",
    "\n",
    "    def get_precomputed_tracks(satellite: int, start: datetime, end: datetime):\n",
    "        \"\"\"\n",
    "        Return a listing of active satellites and positions that spans `start` to `end`\n",
    "        datetimes. The arrays returned will have `times` elements, which correspond to the\n",
    "        number of integer minutes between the starting points of the two arrays.\n",
    "\n",
    "        This returns an array:\n",
    "        @returns np.array (times, 3)\n",
    "\n",
    "        \"\"\"\n",
    "        name = \"s\" + str(satellite)    \n",
    "        assert hasattr(self.node, name), \"No Data for satellite with norad ID: %i\" % norad_id\n",
    "        dataz = getattr(self.node, name)[:]\n",
    "\n",
    "        start_index = np.searchsorted(dataz[0, :], start.timestamp())\n",
    "        end_index   = np.searchsorted(dataz[0, :], end.timestamp())\n",
    "        return dataz[:, start_index: end_index]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_satellites_contained()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t, lat, long, dist = get_precomputed_tracks(312, datetime(2010, 1, 1), datetime(2020, 1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
