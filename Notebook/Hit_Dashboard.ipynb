{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import panel as pn\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import holoviews as hv\n",
    "from colorcet import fire\n",
    "from holoviews.operation.datashader import rasterize\n",
    "from sathelpers import SatelliteDataStore\n",
    "hv.extension('bokeh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set some configuration variables\n",
    "# In general, these should be explicit paths with no variables or homedir (~)\n",
    "AIS_DIR = \"/Users/pwang/data/vault\"\n",
    "SAT_DIR = \"/Users/pwang/data/vault/satellites_active\"\n",
    "\n",
    "if not os.path.isdir(AIS_DIR) or not os.path.isdir(SAT_DIR):\n",
    "    raise IOError(\"Invalid source data directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get metadata\n",
    "\n",
    "Next line is not cross-platform:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://www.ucsusa.org/sites/default/files/2020-10/UCS-Satellite-Database-8-1-2020.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define selector input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0. Configure the input parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on the year of interest, also define the AIS file to look at\n",
    "AIS_FILENAME = \"ais_2015.h5\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. Load the satellite data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "satdata = SatelliteDataStore(SAT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"UCS-Satellite-Database-8-1-2020.txt\", sep='\\t', encoding='L1', low_memory=False) \n",
    "df = df.dropna(axis='columns',how='all')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norad_names = dict(zip(df['Name of Satellite, Alternate Names'], df['NORAD Number']))\n",
    "available_norad_ids = satdata.get_norad_ids()\n",
    "norad_names.pop([el for el in list(norad_names.keys()) if type(el) != str][0]) # Drop nan record\n",
    "norad_names = {k:int(v) for k,v in norad_names.items() if int(v) in available_norad_ids}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = pn.widgets.AutocompleteInput(\n",
    "    name='Satellite', options=list(norad_names.keys()),\n",
    "    placeholder='Satellite name')\n",
    "selector.value = 'International Space Station (ISS [first element Zarya])'\n",
    "selector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. Load the AIS data\n",
    "\n",
    "Since the example in this notebook is from the period of time of 2009, we just need to load its AIS tracks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ais = pd.read_hdf(os.path.join(AIS_DIR, AIS_FILENAME))\n",
    "ais.sort_values(by=\"date_time\", inplace=True)\n",
    "ais.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3. Compute the visible points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../vault/Scripts\")   # TODO\n",
    "import intersect; intersect.PRINT_INFO=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4. Visualize the results\n",
    "\n",
    "Start by defining date pickers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = pn.widgets.DatePicker(name='Start Date', value=dt.date(2015, 1, 1))\n",
    "end_date = pn.widgets.DatePicker(name='End Date', value=dt.date(2015, 1, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vessel_categories = pd.read_csv(\"./AIS_categories.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vessel metadata CSV files for Zones 1,2 and 3 in 2015\n",
    "vessel_info_dict = {}\n",
    "try:\n",
    "    vessel_info_z1 = pd.read_csv(\"./Vessel_Zone1.csv\")\n",
    "    vessel_info_z2 = pd.read_csv(\"./Vessel_Zone2.csv\")\n",
    "    vessel_info_z3 = pd.read_csv(\"./Vessel_Zone3.csv\")\n",
    "    for _, row in list(vessel_info_z1.iterrows()) + list(vessel_info_z2.iterrows()) + list(vessel_info_z3.iterrows()):\n",
    "        vessel_info_dict[int(row['mmsi_id'])] = {'vessel_name':row['vessel_name'], 'length':row['length'], \n",
    "                                             # Problematic due to uninterpretable vessel int ids\n",
    "                                             # 'vessel_type':int(row['vessel_type'])\n",
    "                                             'width':row['width']\n",
    "                                             }\n",
    "except: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiles = hv.element.tiles.ESRI().redim(x='easting', y='northing')\n",
    "\n",
    "def modulo_lon(val):\n",
    "    return (val+180) % 360 - 180\n",
    "\n",
    "def get_track(lat, lon, lat_clip=85.5):\n",
    "    mask = np.abs(lat) > lat_clip\n",
    "    lat[mask] = np.float('nan')\n",
    "    lon[mask] = np.float('nan')\n",
    "    lon = np.array([modulo_lon(el) for el in lon])\n",
    "    \n",
    "    eastings, northings = hv.util.transform.lon_lat_to_easting_northing(lon,lat)\n",
    "    # Heuristic to insert NaNs to break up Curve (prevent wrapping issues at date line)\n",
    "    inds = np.where(np.abs(np.diff(eastings)) > 2e7)[0] # Big delta to split on\n",
    "    inds += 1\n",
    "    eastings  = np.insert(eastings,  inds, [float('nan') for i in range(len(inds))])\n",
    "    northings = np.insert(northings, inds, [float('nan') for i in range(len(inds))])\n",
    "    return hv.Curve((eastings, northings))\n",
    "\n",
    "\n",
    "def get_vessels(hits_df, start_date, end_date):\n",
    "    hits = hits_df.copy() # To be safe\n",
    "    # ['mmsi_id', 'date_time', 'lat', 'lon']\n",
    "    sdate = dt.datetime(start_date.year, start_date.month, start_date.day)\n",
    "    edate = dt.datetime(end_date.year, end_date.month, end_date.day)\n",
    "    middate = sdate + (edate - sdate) / 2\n",
    "    lats, lons = [], []\n",
    "    vessel_names = []\n",
    "    lengths = []\n",
    "    widths = []\n",
    "    for mmsi_id, df in hits.groupby('mmsi_id'):\n",
    "        df['timestamp'] = pd.to_datetime(df['date_time'])\n",
    "        df = df.drop_duplicates().set_index('timestamp') # Assuming sorted avoiding .sort_values(by='timestamp')\n",
    "        idx = df.index.get_loc(middate, method='nearest')\n",
    "        vinfo = vessel_info_dict.get(mmsi_id, {})\n",
    "        vessel_names.append(vinfo.get('vessel_name', 'Unknown'))\n",
    "        lengths.append(vinfo.get('length', 'Unknown'))\n",
    "        widths.append(vinfo.get('width', 'Unknown'))\n",
    "        lats.append(float(df.iloc[idx]['lat']))\n",
    "        lons.append(float(df.iloc[idx]['lon']))\n",
    "        \n",
    "    eastings, northings = hv.util.transform.lon_lat_to_easting_northing(np.array(lons),np.array(lats))\n",
    "    return hv.Points((eastings, northings, vessel_names, lengths, widths), \n",
    "                     vdims=['name', 'length', 'width']).opts(color='white', size=4,  marker='triangle')\n",
    "    \n",
    "def rasterize_hits(name_dict, start_dict, end_dict, plot_size_dict, rangexy_dict):#\n",
    "    name, start_date, end_date = name_dict['value'], start_dict['value'], end_dict['value']\n",
    "    norad_id = int(norad_names[name])\n",
    "    start_time = pd.Timestamp(start_date)\n",
    "    end_time = pd.Timestamp(end_date)\n",
    "    try:\n",
    "        (times, lats, lons, alts) = satdata.get_precomputed_tracks(norad_id,\n",
    "                                                            start=start_time, end=end_time)\n",
    "    except:\n",
    "        return hv.Curve(None)\n",
    "    mask = lons > 180.0\n",
    "    lons[mask] -= 360  # Need longitudes in (-180,180) format, not 0-360\n",
    "    \n",
    "    sat = pd.DataFrame({\"date_time\": times.astype(\"<M8[s]\"),\"lat\": lats, \"lon\": lons, \"alt\": alts})\n",
    "    hits = intersect.compute_hits(sat, ais, \n",
    "                                  start_time=str(start_date), \n",
    "                                  end_time=str(end_date), workers=4)\n",
    "\n",
    "    mask = (np.abs(hits['lat']) < 85)\n",
    "    eastings, northings = hv.util.transform.lon_lat_to_easting_northing(hits['lon'], hits['lat'])\n",
    "    \n",
    "    markers = get_vessels(hits, start_date, end_date).opts(tools=['hover'])\n",
    "    \n",
    "    return rasterize(hv.Points(pd.DataFrame({'northing':northings[mask], \n",
    "                    'easting':eastings[mask]}), ['easting', 'northing']),\n",
    "                             width = int(plot_size_dict['width']),\n",
    "                             height = int(plot_size_dict['height']),\n",
    "                             x_range=rangexy_dict['x_range'],\n",
    "                             y_range=rangexy_dict['y_range'],\n",
    "                             dynamic=False\n",
    "                            ).opts(cmap=fire[180:], width=700, height=500,\n",
    "            cnorm='eq_hist', alpha=0.5) * get_track(lats, lons).opts(color='red') * markers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hits_dmap = hv.DynamicMap(rasterize_hits, \n",
    "                          streams=[selector.param.value,  start_date.param.value, end_date.param.value,\n",
    "                                    hv.streams.PlotSize(width=700, height=500),  hv.streams.RangeXY()],\n",
    "                     positional_stream_args=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=RuntimeWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pn.Column(pn.Row(start_date, end_date), selector, tiles * hits_dmap)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
