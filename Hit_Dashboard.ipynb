{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Panel dashboard for calculating hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import panel as pn\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import param\n",
    "import holoviews as hv\n",
    "from colorcet import fire\n",
    "from panel.template import DarkTheme\n",
    "from io import StringIO\n",
    "from holoviews.operation.datashader import rasterize\n",
    "from bokeh.models.tools import HoverTool\n",
    "from scripts.sathelpers import SatelliteDataStore\n",
    "hv.extension('bokeh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter warnings in hit intersection code\n",
    "warnings.filterwarnings('ignore', category=RuntimeWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Customize display of tables for later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "css = \".bk.bk-data-table {color: black;} .slick-header-columns {color: white; font-weight: bold;}\"\n",
    "pn.config.raw_css.append(css)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set some configuration variables\n",
    "# In general, these should be explicit paths with no variables or homedir (~)\n",
    "AIS_DIR = './data/vessel data/Cleaned AIS'\n",
    "SAT_DIR = './data/satellite data/index'\n",
    "\n",
    "if not os.path.isdir(AIS_DIR) or not os.path.isdir(SAT_DIR):\n",
    "    raise IOError(\"Invalid source data directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0. Configure the input parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on the year of interest, also define the AIS file to look at\n",
    "AIS_FILENAME = \"ais_2015.h5\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. Load the satellite data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "satdata = SatelliteDataStore(SAT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./metadata/UCS-Satellite-Database-8-1-2020.txt\", sep='\\t', encoding='L1', low_memory=False) \n",
    "df = df.dropna(axis='columns',how='all')\n",
    "df.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norad_names = dict(zip(df['Name of Satellite, Alternate Names'], df['NORAD Number']))\n",
    "available_norad_ids = satdata.get_norad_ids()\n",
    "norad_names.pop([el for el in list(norad_names.keys()) if type(el) != str][0]) # Drop nan record\n",
    "norad_names = {k:int(v) for k,v in norad_names.items() if int(v) in available_norad_ids}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. Load the AIS data\n",
    "\n",
    "Since the example in this notebook is from the period of time of 2009, we just need to load its AIS tracks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    ais = pd.read_hdf(os.path.join(AIS_DIR, AIS_FILENAME))\n",
    "    ais.sort_values(by=\"date_time\", inplace=True)\n",
    "    return ais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ais = pn.state.as_cached(\"ais\", load_data)\n",
    "ais.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3. Compute the visible points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts import intersect; intersect.PRINT_INFO=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4. Visualize the results\n",
    "\n",
    "Start by loading vessel metadata:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vessel_categories = pd.read_csv(\"./metadata/AIS_categories.csv\")\n",
    "vessel_df = pd.read_csv(\"./metadata/Vessel.csv\")\n",
    "vessel_info_dict = {row['mmsi_id']:{'vessel_name':row['vessel_name'], 'length':row['length'], \n",
    "'vessel_type': vessel_categories[vessel_categories['num']==(0 if np.isnan(row['vessel_type']) \n",
    "                                 else int(row['vessel_type']))].iloc[0]['desc'],\n",
    "                                    'width':row['width']} for i, row in vessel_df.iterrows()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modulo_lon(val):\n",
    "    return (val+180) % 360 - 180\n",
    "\n",
    "def get_track(lat, lon, lat_clip=85.5):\n",
    "    \"Turn track of latitudes and longitudes into NaN-separated Curve\"\n",
    "    mask = np.abs(lat) > lat_clip\n",
    "    lat[mask] = np.float('nan')\n",
    "    lon[mask] = np.float('nan')\n",
    "    lon = np.array([modulo_lon(el) for el in lon])\n",
    "    \n",
    "    eastings, northings = hv.util.transform.lon_lat_to_easting_northing(lon,lat)\n",
    "    # Heuristic to insert NaNs to break up Curve (prevent wrapping issues at date line)\n",
    "    inds = np.where(np.abs(np.diff(eastings)) > 2e7)[0] # Big delta to split on\n",
    "    inds += 1\n",
    "    eastings  = np.insert(eastings,  inds, [float('nan') for i in range(len(inds))])\n",
    "    northings = np.insert(northings, inds, [float('nan') for i in range(len(inds))])\n",
    "    return hv.Curve((eastings, northings))\n",
    "\n",
    "\n",
    "def grouby_mmsid(hits):\n",
    "    \"Apply a groupby, reindex on sorted datetimes\"\n",
    "    group = {}\n",
    "    for mmsi_id, df in hits.groupby('mmsi_id'):\n",
    "        df['timestamp'] = pd.to_datetime(df['date_time'])\n",
    "        # Assuming sorted avoiding .sort_values(by='timestamp')\n",
    "        group[mmsi_id]= df.drop_duplicates().set_index('timestamp')\n",
    "    return group\n",
    "    \n",
    "table_cols = ['vessel_name', 'mmsi_id', 'vessel_type', 'start_lat', 'end_lat',\n",
    "              'start_lat', 'start_lon', 'length', 'width']\n",
    "def viewable_vessel_df(hits_mmsid_groupby, vessel_info_dict, ):\n",
    "    data = []\n",
    "    for mmsi_id, df in hits_mmsid_groupby.items():\n",
    "        start, end = df.iloc[0], df.iloc[-1]\n",
    "        start_lat, end_lat = start['lat'], end['lat']\n",
    "        start_lon, end_lon = start['lon'], end['lon']\n",
    "        vessel_record = vessel_info_dict.get(mmsi_id, \n",
    "                                             dict({k:'' for k in table_cols}, mmsi_id=mmsi_id))\n",
    "        vessel_info = {k: '' if (isinstance(v, float) and np.isnan(v)) else v\n",
    "                       for k,v in vessel_record.items()}\n",
    "        data.append({'mmsi_id':mmsi_id,'vessel_name':vessel_info['vessel_name'],\n",
    "                     'vessel_type':vessel_info['vessel_type'],\n",
    "                     'start_lat':start_lat, 'end_lat':end_lat,\n",
    "                     'start_lon':start_lon, 'end_lon':end_lon,\n",
    "                     'length':vessel_info['length'], 'width':vessel_info['width']})\n",
    "        \n",
    "    return pd.DataFrame(data).sort_values(by='mmsi_id')\n",
    "        \n",
    "def get_vessels(hits_mmsid_groupby, start_date, end_date, lat_limit=85.5):\n",
    "    \"Mark the vessels in the AIS data at the midpoint between start and end date\"\n",
    "    sdate = dt.datetime(start_date.year, start_date.month, start_date.day)\n",
    "    edate = dt.datetime(end_date.year, end_date.month, end_date.day)\n",
    "    middate = sdate + (edate - sdate) / 2\n",
    "    lats, lons, lengths, widths, vessel_names = [], [], [], [], []\n",
    "    for mmsi_id, df in hits_mmsid_groupby.items():\n",
    "        idx = df.index.get_loc(middate, method='nearest')\n",
    "        vinfo = vessel_info_dict.get(mmsi_id, {})\n",
    "        vessel_names.append(vinfo.get('vessel_name', 'Unknown'))\n",
    "        lengths.append(vinfo.get('length', 'Unknown'))\n",
    "        widths.append(vinfo.get('width', 'Unknown'))\n",
    "        lat = float(df.iloc[idx]['lat'])\n",
    "        lats.append(lat if abs(lat) < lat_limit else float('nan'))\n",
    "        lons.append(float(df.iloc[idx]['lon']) if abs(lat) < lat_limit else float('nan'))\n",
    "        \n",
    "    eastings, northings = hv.util.transform.lon_lat_to_easting_northing(np.array(lons),np.array(lats))\n",
    "    tooltips = [(\"name\", \"@name\"), (\"latitude\", \"@lat\"), (\"longitude\", \"@lon\"),\n",
    "                (\"length\", \"@length\"), (\"width\", \"@width\")]\n",
    "    return hv.Points((eastings, northings, vessel_names, lengths, widths, lats, lons), \n",
    "                     vdims=['name', 'length', 'width', 'lat', 'lon']).opts(color='white', size=4,  marker='triangle', \n",
    "                                                            tools=[HoverTool(tooltips=tooltips)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DynamicMap callback:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rasterize_hits(name_dict, start_dict, end_dict, start_hours_dict, end_hours_dict,\n",
    "                   checkbox_dict, plot_size_dict, rangexy_dict):\n",
    "    \"DynamicMap callback plotting rasterized hits, satellite track and vessel locations\"\n",
    "    name, start_date, end_date = name_dict['value'], start_dict['value'], end_dict['value']\n",
    "    start_hours, end_hours = start_hours_dict['value'], end_hours_dict['value']\n",
    "    full_range = checkbox_dict['value']\n",
    "    norad_id = int(norad_names[name])\n",
    "    start_time = pd.Timestamp(year=start_date.year, month=start_date.month, day=start_date.day,\n",
    "                              hour = start_hours.hour, minute=start_hours.minute, second=start_hours.second)\n",
    "    \n",
    "    end_time = pd.Timestamp(year=end_date.year, month=end_date.month, day=end_date.day,\n",
    "                            hour = end_hours.hour, minute=end_hours.minute, second=end_hours.second)\n",
    "    if full_range:\n",
    "        start_time, end_time = satdata.get_timespan(norad_id)\n",
    "    try:\n",
    "        (times, lats, lons, alts) = satdata.get_precomputed_tracks(norad_id, start=start_time, end=end_time)\n",
    "    except: \n",
    "        print('Exception in get_precomputed_tracks: %s' % str(e))\n",
    "        return hv.Overlay([])\n",
    "\n",
    "    # Need longitudes in (-180,180) format, not 0-360\n",
    "    mask = lons > 180.0\n",
    "    lons[mask] -= 360  \n",
    "    \n",
    "    try:\n",
    "        sat = pd.DataFrame({\"date_time\": times.astype(\"<M8[s]\"),\"lat\": lats, \"lon\": lons, \"alt\": alts})\n",
    "        hits = intersect.compute_hits(sat, ais, start_time=start_time, end_time=end_time, workers=4)\n",
    "    except Exception as e:\n",
    "        print('Exception in compute_hits: %s' % str(e))\n",
    "        return hv.Overlay()\n",
    "\n",
    "    hits_mmsid_groupby = grouby_mmsid(hits)\n",
    "    hit_vessel_info = viewable_vessel_df(hits_mmsid_groupby, vessel_info_dict)\n",
    "    drilldown.selection = hit_vessel_info\n",
    "    mask = (np.abs(hits['lat']) < 85)\n",
    "    eastings, northings = hv.util.transform.lon_lat_to_easting_northing(hits['lon'], hits['lat'])\n",
    "    rasterim = rasterize(hv.Points(pd.DataFrame({'northing':northings[mask], \n",
    "                    'easting':eastings[mask]}), ['easting', 'northing']),\n",
    "                             width = int(plot_size_dict['width']), height = int(plot_size_dict['height']),\n",
    "                             x_range=rangexy_dict['x_range'], y_range=rangexy_dict['y_range'], dynamic=False\n",
    "                            ).opts(cmap=fire[180:], width=700, height=500, cnorm='eq_hist', alpha=0.5)\n",
    "\n",
    "    elements = [rasterim]\n",
    "    if not full_range:\n",
    "        elements += [get_track(lats, lons).opts(color='red'),\n",
    "                     get_vessels(hits_mmsid_groupby, start_date, end_date)]\n",
    "    return hv.Overlay(elements)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declaring panel widgets\n",
    "\n",
    "Satellite selector widgets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "satellites = list(norad_names.keys())\n",
    "constellations = sorted(list(set([re.sub(r'[ -].*', '', str(s)) for s in satellites])))\n",
    "constellation = pn.widgets.Select(options=constellations, name=\"Constellation\", sizing_mode='stretch_width')\n",
    "constellation.value = 'International'\n",
    "satellite = pn.widgets.Select(options=[s for s in satellites \n",
    "                                       if re.match(constellation.value, str(s))], \n",
    "                              sizing_mode='stretch_width', name=\"Satellite\")\n",
    "\n",
    "@pn.depends(constellation.param.value, watch=True)\n",
    "def update_satellite_options(constellation):\n",
    "    satellite.options = [s for s in satellites if re.match(constellation, str(s))]\n",
    "    satellite.value = satellite.options[0] if satellite.options else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The drilldown table and download CSV callback:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_df = pd.DataFrame({el:[] for el in table_cols})\n",
    "\n",
    "class Drilldown(param.Parameterized):\n",
    "    selection = param.DataFrame(empty_df)\n",
    "    \n",
    "    @param.depends('selection')\n",
    "    def update_table(self, *args, **kwargs):\n",
    "        return pn.widgets.DataFrame(self.selection, show_index=False, \n",
    "                                    autosize_mode='fit_columns', height=400, width=700)\n",
    "    \n",
    "    def csv_download(self):\n",
    "        sio = StringIO()\n",
    "        self.selection.to_csv(sio)\n",
    "        sio.seek(0)\n",
    "        return sio\n",
    "    \n",
    "drilldown = Drilldown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_button = pn.widgets.FileDownload(\n",
    "    callback=drilldown.csv_download, filename='hits.csv', sizing_mode='stretch_width')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Date and checkbox widgets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = pn.widgets.DatePicker(name='Start Date', value=dt.date(2015, 1, 1), width=100, sizing_mode='stretch_width')\n",
    "end_date = pn.widgets.DatePicker(name='End Date', value=dt.date(2015, 1, 4), width=100, sizing_mode='stretch_width')\n",
    "full_range = pn.widgets.Checkbox(name='Full date range', sizing_mode='stretch_width')\n",
    "map_opacity = pn.widgets.FloatSlider(name='Map opacity', value=0.7, start=0.0, end=1.0, sizing_mode='stretch_width')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time widgets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_hours = dt.datetime(2020, 1, 1, 0, 0, 0, 0)\n",
    "twelve_hours = dt.datetime(2020, 1, 1, 12, 0, 0, 0)\n",
    "start_time = pn.widgets.DatetimeInput(value=zero_hours, format=\"%H:%M\", \n",
    "                                      width=80, name='Start Time', align='end', sizing_mode='stretch_width')\n",
    "end_time = pn.widgets.DatetimeInput(value=twelve_hours, format=\"%H:%M\", \n",
    "                                    width=80, name='End Time', align='end', sizing_mode='stretch_width')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up callback to disable date pickers when 'full date range' checkbox active:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pn.depends(full_range.param.value, watch=True)\n",
    "def disable_callback(full_range):\n",
    "    start_date.disabled = full_range\n",
    "    end_date.disabled = full_range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declaring HoloViews elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiles = hv.element.tiles.ESRI().redim(x='easting', y='northing').opts(bgcolor=\"black\").apply.opts(alpha=map_opacity)\n",
    "hits_dmap = hv.DynamicMap(rasterize_hits, \n",
    "                          streams=[satellite.param.value,  start_date.param.value, end_date.param.value,\n",
    "                                   start_time.param.value, end_time.param.value, full_range.param.value,\n",
    "                                   hv.streams.PlotSize(width=700, height=500),  hv.streams.RangeXY()],\n",
    "                     positional_stream_args=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declaring Panel dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions = \"\"\"\n",
    "Select a date/time range and a satellite, and this dashboard will show you the track \n",
    "of that satellite over the time range, plus the vessels visible from that satellite. \n",
    "Zoom around Alaska to see the vessels in detail, after selecting \n",
    "the Scroll Zoom tool on the plot.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz = pn.Column(pn.pane.Markdown(instructions, width=800), \n",
    "                pn.Row(tiles.opts(padding=0) * hits_dmap.opts(padding=0), drilldown.update_table))\n",
    "all_widgets = pn.Column(full_range, pn.Row(start_date, start_time, sizing_mode='stretch_width'), \n",
    "                        pn.Row(end_date, end_time, sizing_mode='stretch_width'), constellation, \n",
    "                        satellite, map_opacity, download_button, sizing_mode='stretch_width')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pn.Column(all_widgets, viz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = pn.template.MaterialTemplate(title='AIS Visibility Dashboard', theme=DarkTheme, \n",
    "                                        logo='./Doc/images/combined.png')\n",
    "template.sidebar.append(all_widgets)\n",
    "template.main.append(viz)\n",
    "template.servable();"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
