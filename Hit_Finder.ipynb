{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hit Detection Notebook\n",
    "\n",
    "This notebook demonstrates how to find the vessels and times that a particular satellite was able to see.\n",
    "\n",
    "## Pre-requisites\n",
    "\n",
    "This notebook presumes that data processing and precompute has already been completed. Please see the **Data Preparation** notebook.\n",
    "\n",
    "Required libraries for this notebook (not the pre-computation one):\n",
    "\n",
    "  * Numpy 1.19.2\n",
    "  * Pandas v1.1.5\n",
    "  * Numba 0.51.2\n",
    "  * Holoviews 1.14\n",
    "  * Bokeh 2.2.3\n",
    "  * Datashader 0.11.1\n",
    "  * PyTables 3.6.1\n",
    "  * Jupyter (core=4.7, client=6.1.7)\n",
    "\n",
    "These should be installed via `conda`, from the default Anaconda repository (not Conda-Forge).\n",
    "\n",
    "The `skyfield` library should be installed via `pip`.  It is very important that `skyfield` version is 1.35, and the `sgp4` library that it installs is v2.14.\n",
    "\n",
    "## Data and Locations\n",
    "\n",
    "The required data variables are described below:\n",
    "\n",
    "| Variable | Description | S3 location | \n",
    "| --- | :- | :- |\n",
    "| `AIS_DIR` | Location of ais_????.h5 files or ais_????.interp.h5 files | `s3://anaconda-hit-finder-prod/AIS` or `s3://anaconda-hit-finder-prod/AIS_interp` |\n",
    "| `SAT_DIR` | Location of precomputed satellite tracks. | `s3://anaconda-hit-finder-prod/satellites_active` or `s3://anaconda-hit-finder-prod/satellites_all` | \n",
    "\n",
    "By default, `AIS_DIR` is set to the current working directory (CWD) of this noteboook, and `SAT_DIR` looks for a directory called `satellites/` in the current directory.\n",
    "\n",
    "## A comment on hardware\n",
    "\n",
    "This algorithm is heavily parallelized and can take advantage of all cores on the machine.\n",
    "\n",
    "Development was done on a Macbook Pro with 4 cores and 16 GB of memory, and Amazon AWS EC2 instances of type `m5zn.6xlarge` and `t3.2xlarge`. The target deployment environment is a workstation-grade 8 or 16 core machine with 16GB of memory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial setup\n",
    "# Make the notebook wider\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "display(HTML(data=\"\"\"\n",
    "<style>\n",
    "    div#notebook-container    { width: 95%; }\n",
    "    div#menubar-container     { width: 65%; }\n",
    "    div#maintoolbar-container { width: 99%; }\n",
    "</style>\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import os\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set some configuration variables\n",
    "# In general, these should be explicit paths with no variables or homedir (~)\n",
    "AIS_DIR = \"data/vessel data/Cleaned AIS\"\n",
    "SAT_DIR = \"data/satellite data/index_active\"\n",
    "\n",
    "if not os.path.isdir(AIS_DIR) or not os.path.isdir(SAT_DIR):\n",
    "    raise IOError(\"Invalid source data directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 0. Configure the input parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The satellite we're interested in\n",
    "norad_id = 25544  # The International Space Station\n",
    "\n",
    "# The start and end times we're interested in.  For the sake of simplicity in\n",
    "# this notebook, we are restricting to just one year.  The Python script\n",
    "# is able to query multiple years.\n",
    "start_time = pd.Timestamp(\"2014-12-31T00:00:01\")\n",
    "end_time = pd.Timestamp(\"2015-02-01T00:00:00\")\n",
    "\n",
    "# Based on the year of interest, also define the AIS file to look at\n",
    "AIS_FILENAME = \"ais_2015.h5\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Step 1. Load the satellite data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.sathelpers import SatelliteDataStore\n",
    "satdata = SatelliteDataStore(SAT_DIR)\n",
    "\n",
    "(times, lats, lons, alts) = satdata.get_precomputed_tracks(norad_id, start=start_time,\n",
    "        end=end_time)\n",
    "# The longitudes in the pre-computed satellite tracks range from 0-360,\n",
    "# but we need them in (-180,180) format.\n",
    "mask = lons > 180.0\n",
    "lons[mask] -= 360\n",
    "\n",
    "# Now convert to a dict that can by passed in to the intersection calculation\n",
    "sat = pd.DataFrame({\"date_time\": times.astype(\"<M8[s]\"),\n",
    "       \"lat\": lats, \"lon\": lons, \"alt\": alts})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2. Load the AIS data\n",
    "\n",
    "Since the example in this notebook is from the period of time of 2009, we just need to load its AIS tracks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ais = pd.read_hdf(os.path.join(AIS_DIR, AIS_FILENAME))\n",
    "ais.sort_values(by=\"date_time\", inplace=True)\n",
    "ais.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3. Compute the visible points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts import intersect; intersect.PRINT_INFO=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(intersect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hits = intersect.compute_hits(sat, ais, start_time=\"2015-01-01\", end_time=\"2015-01-17\", workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(hits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hits2 = intersect.compute_hits(sat, ais, start_time=\"2015-01-01\", end_time=\"2015-01-17\", workers=4, assume_half_earth=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(hits2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4. Visualize the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import panel as pn\n",
    "import datetime as dt\n",
    "import holoviews as hv\n",
    "from colorcet import fire\n",
    "from holoviews.operation.datashader import rasterize\n",
    "hv.extension('bokeh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plot_helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = plot_helpers.plot_points(hits)\n",
    "#t2 = plot_helpers.plot_points(hits2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pn.Row(t).servable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
