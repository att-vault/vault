{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Viewing AIS data\n",
    "\n",
    "This [Jupyter](https://jupyter.org) notebook explores and analyzes the [Automatic Identification System (AIS)](https://en.wikipedia.org/wiki/Automatic_identification_system) vessel-location data provided for the 12/2020 VAULT technical scenario, showing what data is available and how it can be accessed and visualized from Python. The notebook also acts as a runnable application that can be put on a server to allow users to explore the data interactively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import panel as pn\n",
    "import datetime as dt\n",
    "import holoviews as hv\n",
    "import colorcet as cc\n",
    "import param\n",
    "from holoviews.util.transform import lon_lat_to_easting_northing as ll2en\n",
    "from holoviews.operation.datashader import rasterize, dynspread\n",
    "hv.extension('bokeh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data has been provided for four [UTM zones](https://en.wikipedia.org/wiki/Universal_Transverse_Mercator_coordinate_system#UTM_zone) (1, 2, 3, and 10), with vessels identified by their [Maritime Mobile Service Identity](https://en.wikipedia.org/wiki/Maritime_Mobile_Service_Identity) numbers. Data for zones 1-3 was provided as CSVs that can be loaded directly in Python, while the zone 10 data was converted to CSV using `ogr2ogr` from the provided GDB files. `ogr2ogr` produces several CSVs per GDB file, and here we focus only on Broadcast.csv. The column names in Broadcast.csv are slightly different from zone1-3 files, so we'll set up a mapping between the column names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnmap = dict(mmsi_id='MMSI', date_time='BaseDateTime', lat='LAT', lon='LON', speed_over_ground='SOG', \n",
    "                 course_over_ground='COG', heading='Heading', status='Status')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll write a function that uses [pandas](https://pandas.pydata.org) to load 2017 data from zones 1-3 and 2014 data from zone 10:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    print(\"Loading data...\")\n",
    "    zone1 = pd.read_csv('./data/vessel data/AIS/AIS_2017_01_Zone01.csv', parse_dates=[1])\n",
    "    zone2 = pd.read_csv('./data/vessel data/AIS/AIS_2017_01_Zone02.csv', parse_dates=[1])\n",
    "    zone3 = pd.read_csv('./data/vessel data/AIS/AIS_2017_01_Zone03.csv', parse_dates=[1])\n",
    "    zone10= pd.read_csv('./data/vessel data/Cleaned AIS/Zone10_2014_01/Broadcast.csv', parse_dates=[1])\n",
    "    zone10.columns = [columnmap.get(c,c) for c in zone10.columns]\n",
    "    zones = pd.concat([zone1,zone2, zone3, zone10])\n",
    "    \n",
    "    print(\"Projecting data...\") # For later plotting\n",
    "    zones.loc[:,'x'], zones.loc[:,'y'] = ll2en(zones.LON,zones.LAT)\n",
    "    \n",
    "    print(\"Grouping by vessel...\")\n",
    "    vessels = {name:df.drop_duplicates().sort_values(by='BaseDateTime').set_index('BaseDateTime') \n",
    "               for name,df in zones.groupby('VesselName')}\n",
    "    return zones, vessels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then load the files, using the `pn.state.as_cached` function to cache the data to ensure that only the first visitor to our app (below) has to load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "zones, vessels = pn.state.as_cached('zones, vessels', load_data)\n",
    "zones.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The AIS files include a variety of data and metadata values about each reported AIS broadcast. As we can see by looking at the first few rows of data, some of these values indicate the current state (e.g. LAT, LON, SOG, COG, Heading at the given time), while the others indicate metadata about the vessel (VesselName, CallSign, etc.):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Together this set of four files has more than 20 million records (AIS pings). Not all columns are present for every record, but some could be filled in using publicly available data (or replaced with a placeholder, such as using MMSI for a missing (NaN) VesselName).\n",
    "\n",
    "Because the eventual task involves matching vessel locations to satellite fields of view, let's visualize the set of locations available using [HoloViews](https://holoviews.org):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = rasterize(hv.Points(zones, ['LON','LAT'])).opts(cnorm='eq_hist', aspect='equal')\n",
    "points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To zoom in & interact with the plot, click the “Wheel zoom” tool in the toolbar on the side of the plot.\n",
    "Click-and-drag the plot in order to look around.  As you zoom in, finer-grained detail will emerge and fill in.  Depending on the size of the dataset and your machine, this might take a second."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here HoloViews generates an interactive [Bokeh](https://bokeh.org) plot that uses [Datashader](https://datashader.org) to compute a heatmap for location data, with darker blue colors indicating pixels with more AIS data \"pings\". With an interactive Python session running, you can zoom into the above heatmap plot to see how the location data is distributed. E.g. if we zoom into the densest region of AIS points in the top left, we can see a lot of interesting structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = hv.Points(zones, ['LON','LAT'])\n",
    "\n",
    "dynspread(rasterize(points, width=800, height=300, x_range=(-169,-162), y_range=(53.5,56))\\\n",
    "  .opts(width=800, height=300, cnorm='eq_hist', tools=['hover']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To put this data in context, we'll plot it on a map using a public map tile source in Web Mercator coordinates, so we'll use the easting,northing values projected previously. Let's also create some annotations that show the UTM zone boundaries, to validate that the data provided is indeed in the zones listed in the filenames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zone(i):\n",
    "    \"\"\"\n",
    "    Return plottable bounds object for a given UTM zone\n",
    "    (see https://en.wikipedia.org/wiki/Universal_Transverse_Mercator_coordinate_system#UTM_zone)\n",
    "    \"\"\"\n",
    "    m    = ll2en((-180+6*(i-1),-180+6*i),(-80,84))\n",
    "    bnds = hv.Bounds((m[0][0], m[1][0], m[0][1], m[1][1])).opts(color=\"white\") \n",
    "    text = hv.Text(m[0][0] + (m[0][1]-m[0][0])/2, 0, f\"{i}\").opts(color=\"white\", text_font_size=\"5pt\")\n",
    "    return bnds * text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's set up some defaults, including a suitable lon,lat range and a colormap going from red to yellow to white so that it shows up against the dark ocean:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_range, y_range = ll2en([-180-45,-80], [-3,60])\n",
    "bounds = dict(x=tuple(x_range), y=tuple(y_range))\n",
    "opts = hv.opts.Image(cmap=cc.fire[64:], width=900, height=500, cnorm='eq_hist', alpha=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now plot the data on top of a map, with bounding boxes for the UTM zones, using `*` to overlay each item:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = rasterize(hv.Points(zones, ['x','y']).redim.range(**bounds)).opts(opts)\n",
    "tiles  = hv.element.tiles.EsriImagery().opts( alpha=0.5, bgcolor='black')\n",
    "labels = hv.element.tiles.StamenLabels().opts(alpha=0.7, level='annotation')\n",
    "\n",
    "tiles * dynspread(points) * zone(1) * zone(2) * zone(3) * zone(10) * labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zooming and panning (selecting appropriate tools from the plot toolbar if needed) should reveal that these vessels provide many AIS pings around ports and in shipping lanes, as well as revealing other interesting trajectories and movement patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting a vessel at a given time\n",
    "\n",
    "The above plots show the cumulative AIS location data over all times available in the files. If we are given a _particular_ time, we can can overlay markers for each vessel on top of the cumulative location data, showing the location of that vessel at the given time. There can be large gaps in the AIS data, so we interpolate between the most recent and the next AIS pings for the given time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = list([el for el in zones.columns if el!= 'BaseDateTime'])\n",
    "\n",
    "def interpolate_position(time, match_start, match_end):\n",
    "    slon, slat = match_start['LON'], match_start['LAT']\n",
    "    elon, elat = match_end[  'LON'], match_end[  'LAT']\n",
    "\n",
    "    delta = match_end.name - match_start.name\n",
    "    interval = time - match_start.name\n",
    "    ratio = (interval / delta)\n",
    "    lon_delta = (elon - slon) * ratio\n",
    "    lat_delta = (elat - slat) * ratio\n",
    "    mlon, mlat = (slon + lon_delta), (slat + lat_delta)           \n",
    "    return (slon, slat), (mlon, mlat), (elon, elat)\n",
    "\n",
    "def vessel_at_time(vessel_name, time, vessels):\n",
    "    df = vessels[vessel_name].drop_duplicates()\n",
    "    if (time < df.index[0]) or (time > df.index[-1]):\n",
    "        return None, None, None, None # Query before first or after last value\n",
    "    try:\n",
    "        idx = df.index.get_loc(time, method='ffill')\n",
    "        match_start = df.iloc[idx]\n",
    "        try:\n",
    "            match_end = df.iloc[idx+1] # df.index.get_loc(time, method='bfill')\n",
    "        except:\n",
    "            match_end = match_start\n",
    "        spos, mpos, epos = interpolate_position(time, match_start, match_end)\n",
    "        return spos, mpos, epos, match_start\n",
    "    except Exception as e:\n",
    "        return None, None, None, None\n",
    "\n",
    "marked_points = None # TODO: Declare a class and make this an attribute\n",
    "def mark_vessels(value, show_segments=False):\n",
    "    \"\"\"Mark vessel location along with optional gap display\"\"\"\n",
    "    global marked_points\n",
    "    records = []\n",
    "    segment_data1 = []\n",
    "    segment_data2 = []\n",
    "    empty = dict({'x':0., 'y':0., 'time':''}, **{col:'' for col in columns})\n",
    "    for vessel in list(vessels.keys()): \n",
    "        spos, mpos, epos, match = vessel_at_time(vessel, value, vessels)\n",
    "        if match is not None:\n",
    "            mx, my = ll2en(mpos[0], mpos[1])\n",
    "            info = dict({'LON':mpos[0], 'LAT':mpos[1]}, **{col:match[col] for col in columns})\n",
    "            records.append(dict(info, **{'x':mx, 'y':my, 'time':match.name}))\n",
    "            sx, sy = ll2en(spos[0], spos[1])\n",
    "            ex, ey = ll2en(epos[0], epos[1])\n",
    "            segment_data1.append((sx,sy,mx,my))\n",
    "            segment_data2.append((mx,my,ex,ey))            \n",
    "    markers = pd.DataFrame(records if len(records) != 0 else [empty]) \n",
    "    alpha = 1 if len(records) else 0\n",
    "    segments1 = hv.Segments(np.array(segment_data1)) if len(segment_data1) else hv.Segments([(0,0,0,0)])\n",
    "    segments2 = hv.Segments(np.array(segment_data2)) if len(segment_data2) else hv.Segments([(0,0,0,0)])\n",
    "    marked_points = hv.Points(markers, ['x', 'y'], columns).opts(color='white', size=4, \n",
    "                                                                 marker='triangle', \n",
    "                                                                 tools=['tap'], \n",
    "                                                                 alpha=alpha)\n",
    "    return (segments1.opts(color='green', nonselection_alpha=1, alpha=show_segments) \n",
    "            * segments2.opts(color='green', line_dash='dotted', nonselection_alpha=1, alpha=show_segments) \n",
    "            * marked_points) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take the midpoint of the 2017 times available in the file, as an example time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "times = zones.BaseDateTime\n",
    "times = times[times.dt.year == 2017]\n",
    "midpoint = times.min() + (times.max() - times.min())/2\n",
    "midpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can compute the locations of each vessel near that time, and overlay that on the points and map tiles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = rasterize(hv.Points(zones, ['x','y']).redim.range(**bounds)).opts(opts)\n",
    "\n",
    "tiles * dynspread(points) * mark_vessels(midpoint).opts(hv.opts.Points(tools=['hover']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now when you hover over the white markers indicating the position of a vessel, you should see lots of information about it.\n",
    "\n",
    "# User interface for selecting a given time and vessel\n",
    "\n",
    "Instead of editing Python code to specify a time, let's add a [Panel](https://panel.holoviz.org) widget to let the user select a specific time interactively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_input = pn.widgets.DatetimeInput(name='Datetime', value=midpoint)\n",
    "dt_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, as the data can be unwieldy in hover form, we can also provide it in a separate table, accessed by clicking on one of the ship markers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_cols = ['MMSI', 'VesselName', 'VesselType', 'Heading', 'CallSign', 'Length', 'Width', 'Cargo']\n",
    "empty_df = pd.DataFrame({el:[] for el in table_cols})\n",
    "\n",
    "class Drilldown(param.Parameterized):\n",
    "    selection = param.DataFrame(empty_df)\n",
    "    \n",
    "    @param.depends('selection')\n",
    "    def update_table(self, *args, **kwargs):\n",
    "        return pn.widgets.DataFrame(self.selection, show_index=False, width=800)\n",
    "    \n",
    "drilldown = Drilldown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mark_vessel_drilldown(value, index, show_segments=True):\n",
    "    if len(index) > 0:\n",
    "        rows = [marked_points.data.iloc[ind] for ind in index]\n",
    "        df = pd.DataFrame(rows)[table_cols]\n",
    "        df.columns = table_cols\n",
    "        drilldown.selection = df\n",
    "\n",
    "    return mark_vessels(value, show_segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = dynspread(rasterize(hv.Points(zones, ['x','y']).redim.range(**bounds))).opts(opts)\n",
    "\n",
    "title = \"# AIS vessel locations\"\n",
    "\n",
    "message = (\"Select a time covered by this dataset and press return to see vessel locations at that time \"\n",
    "           \"(after a few seconds, due to unoptimized time-filtering code). Then click on a vessel \"\n",
    "           \"to see more information about it. Green lines indicate large AIS gaps, connecting the\"\n",
    "           \"vessel to its pings before (solid) and after (dash) the current position.\")\n",
    "\n",
    "dmap = hv.DynamicMap(mark_vessel_drilldown, streams=[dt_input.param.value, hv.streams.Selection1D()])\n",
    "overlay2 = (tiles * points * dmap)\n",
    "pn.Column(title, message, dt_input, overlay2, drilldown.update_table).servable()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This app can now be launched as a separate server using a command like `panel serve <notebookname>.ipynb`, then visiting the URL that is printed as output."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
